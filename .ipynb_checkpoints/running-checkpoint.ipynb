{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "import h5py as h # ver = 2.9.0\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf = h.File(join('data_to_keras', 'vist_dataset.hdf5'), 'r')\n",
    "#hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['test', 'train', 'val']>\n"
     ]
    }
   ],
   "source": [
    "# 'train', 'test', 'val'\n",
    "print(hdf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5055, 5, 1024)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf['train/img'].shape # all image features\n",
    "# 1024 img features: np.ndarray, float32, shape = 5055, 5, 1024\n",
    "# - 5055 stories/sequences\n",
    "# - 5 images per sequence\n",
    "# - 1024 features per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5055, 5, 1024)\n",
      "(5055, 5, 1024)\n",
      "(5055, 5, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(hdf['train/img'].shape)\n",
    "print(hdf['val/img'].shape)\n",
    "print(hdf['test/img'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5055, 5, 73)\n",
      "[   1   25 2615 1189  103    3   50   35   17 3924  199   20    2    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# all txt tokens\n",
    "# txt token indices padded: np.ndarray, int,\n",
    "print(hdf['train/txt'].shape)\n",
    "# 0 is the index of the padding token.\n",
    "print(hdf['train/txt'][0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5055, 5)\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# net length of each sentences\n",
    "# sentence length: np.ndarray, int, shape = 5055, 5\n",
    "print(hdf['train/len_txt'].shape)\n",
    "print(hdf['train/len_txt'][0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5055,)\n",
      "47175\n"
     ]
    }
   ],
   "source": [
    "# storyid for each datasets\n",
    "# np.ndarray, int, shape 5055\n",
    "print(hdf['train/storyid'].shape)\n",
    "print(hdf['train/storyid'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join('data_to_keras', 'modif_vocab_4_plain.pkl'), 'rb') as f:\n",
    "    modif_vocab_4_plain = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11928\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(modif_vocab_4_plain['idx2word'].keys())\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = list(modif_vocab_4_plain['idx2word'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(token_ids[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11927, 11928)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(token_ids[1:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "officiant\n",
      "vowels\n",
      "muse\n",
      "vic\n",
      "lorrie\n",
      "elaine\n",
      "lagunitas\n"
     ]
    }
   ],
   "source": [
    "for i in range(11921,len(modif_vocab_4_plain['idx2word'].keys())):\n",
    "    print(modif_vocab_4_plain['idx2word'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5055, 5, 73, 11921)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(hdf.get('train/txt'))[()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5055, 5, 73, 11921)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(hdf.get('test/txt'))[()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5055, 5, 73, 11921)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(hdf.get('val/txt'))[()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11927"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(modif_vocab_4_plain['idx2word'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Keras Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Seq2Seq model configurations__\n",
    "* LSTM cell\n",
    "* Encoder LSTM depth = 2\n",
    "* Decoder LSTM depth = 1\n",
    "\n",
    "\n",
    "__Optimizer configurartions__\n",
    "* Loss: (stable) cross-entropy\n",
    "* Adam optimzer\n",
    "* `learning_rate = 10**(-3)\n",
    "* `batch_size = 64`\n",
    "* `weight decay = 1e-5`\n",
    "\n",
    "__Reguarization configurations__\n",
    "* Dropout rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seq2seq\n",
    "import tensorflow as tf\n",
    "import h5py as h # ver = 2.9.0\n",
    "import numpy as np\n",
    "from seq2seq.models import AttentionSeq2Seq\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from os.path import join\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf = h.File(join('data_to_keras', 'vist_dataset.hdf5'), 'r')\n",
    "X_train = hdf.get('train/img')[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_seq = hdf.get('train/txt')[()][:,0:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5055, 2, 73)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5055, 146)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_seq = np.reshape(Y_train_seq, (Y_train_seq.shape[0], -1))\n",
    "Y_train_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(5055, 5, 1024)\n",
      "(5055, 146, 11896)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(Y_train))\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, output_length, vocab_size = Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentionSeq2Seq(output_dim=vocab_size, output_length=output_length, batch_input_shape=None,\n",
    "                     batch_size=None, input_shape=None, input_length=5,\n",
    "                     input_dim=1024, hidden_dim=256, depth=(2,1),\n",
    "                     bidirectional=False, unroll=False, stateful=False, dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = AttentionSeq2Seq(input_dim=5, input_length=, hidden_dim=10, output_length=8, output_dim=20, depth=4)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-3, decay=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5055/5055 [==============================] - 64s 13ms/step - loss: 14.9614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0eb15bdc88>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=1, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
